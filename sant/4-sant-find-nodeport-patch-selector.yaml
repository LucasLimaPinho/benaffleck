apiVersion: argoproj.io/v1alpha1
kind: Workflow
metadata:
  generateName: find-nodeport-
  namespace: argo
spec:
  entrypoint: find-nodeport
  templates:
  
  - name: find-nodeport
    steps:
    - - name: allocate-nodeports
        template: allocate
    - - name: pyspark-executor
        template: pyspark
    - - name: deallocate-nodeports
        template: deallocate
        arguments:
          parameters:
          - name: svcname01
            value: "{{steps.allocate-nodeports.outputs.parameters.svcname01}}"
          - name: svcname02
            value: "{{steps.allocate-nodeports.outputs.parameters.svcname02}}"

  - name: allocate
    container:
      image: pinholuc/gut-sant:latest
      command: [python]
      args: [./find_nodeport_patch_selector.py]
    outputs:
      parameters:
      - name: svcname01
        valueFrom:
          path: /tmp/svcname1.txt
      - name: svcname02
        valueFrom:
          path: /tmp/svcname2.txt

  - name: pyspark
    metadata:
      labels:
        user: x247451
    container:
      image: docker/whalesay:latest
      command: [cowsay]
      args: ["py-spark notebook executed. Next step is to deallocate nodeports :)"]

  - name: deallocate
    inputs:
      parameters:
      - name: svcname01
      - name: svcname02
    container:
      image: pinholuc/gut-sant:latest
      command: [python]
      args: [./deallocate_nodeport.py]
      env:
        - name: SERVICE_NAME_01
          value: "{{inputs.parameters.svcname01}}"
        - name: SERVICE_NAME_02
          value: "{{inputs.parameters.svcname02}}"


